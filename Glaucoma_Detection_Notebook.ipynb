{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC as svc\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19, Xception, ResNet50, MobileNet\n",
    "from keras.models import Model\n",
    "from keras.layers import Input \n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are next going to import the necessary tools to use ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/classification_models.git\n",
      "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-c5t6csjr\n",
      "  Running command git clone -q https://github.com/qubvel/classification_models.git /tmp/pip-req-build-c5t6csjr\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Collecting keras_applications<=1.0.8,>=1.0.7\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 772 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.19.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.15.0)\n",
      "Building wheels for collected packages: image-classifiers\n",
      "  Building wheel for image-classifiers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-py3-none-any.whl size=20030 sha256=b23c5a98431478e41e587caa02091b3f9843f0c3e36fbc5be4b27785b7b1d453\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jws23ujn/wheels/0b/96/56/27b17c903efc647c51e4f364bfc20aa67f8d3dccad63c4fb4e\n",
      "Successfully built image-classifiers\n",
      "Installing collected packages: keras-applications, image-classifiers\n",
      "Successfully installed image-classifiers-1.0.0 keras-applications-1.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/qubvel/classification_models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.keras import Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefugeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, split='train', output_size=(256,256)):\n",
    "        # Define attributes\n",
    "        self.output_size = output_size\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        \n",
    "        # Load data index\n",
    "        with open(os.path.join(self.root_dir, self.split, 'index.json')) as f:\n",
    "            self.index = json.load(f)\n",
    "            \n",
    "        self.images = []\n",
    "        for k in range(len(self.index)):\n",
    "            print('Loading {} image {}/{}...'.format(split, k, len(self.index)), end='\\r')\n",
    "            img_name = os.path.join(self.root_dir, self.split, 'images', self.index[str(k)]['ImgName'])\n",
    "            img = np.array(Image.open(img_name).convert('RGB'))\n",
    "            img = transforms.functional.to_tensor(img)\n",
    "            img = transforms.functional.resize(img, self.output_size, interpolation=Image.BILINEAR)\n",
    "            self.images.append(img)\n",
    "            \n",
    "        # Load ground truth for 'train' and 'val' sets\n",
    "        if split != 'test':\n",
    "            self.segs = []\n",
    "            for k in range(len(self.index)):\n",
    "                print('Loading {} segmentation {}/{}...'.format(split, k, len(self.index)), end='\\r')\n",
    "                seg_name = os.path.join(self.root_dir, self.split, 'gts', self.index[str(k)]['ImgName'].split('.')[0]+'.bmp')\n",
    "                seg = np.array(Image.open(seg_name)).copy()\n",
    "                seg = 255. - seg\n",
    "                od = (seg>=127.).astype(np.float32)\n",
    "                oc = (seg>=250.).astype(np.float32)\n",
    "                od = torch.from_numpy(od[None,:,:])\n",
    "                oc = torch.from_numpy(oc[None,:,:])\n",
    "                od = transforms.functional.resize(od, self.output_size, interpolation=Image.NEAREST)\n",
    "                oc = transforms.functional.resize(oc, self.output_size, interpolation=Image.NEAREST)\n",
    "                seg = torch.cat([od, oc], dim=0)\n",
    "                self.segs.append(seg)\n",
    "                \n",
    "        print('Succesfully loaded {} dataset.'.format(split) + ' '*50)\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Image\n",
    "        img = self.images[idx]\n",
    "    \n",
    "        # Return only images for 'test' set\n",
    "        if self.split == 'test':\n",
    "            return img\n",
    "        \n",
    "        # Else, images and ground truth\n",
    "        else:\n",
    "            # Label\n",
    "            lab = torch.tensor(self.index[str(idx)]['Label'], dtype=torch.float32)\n",
    "\n",
    "            # Segmentation masks\n",
    "            seg = self.segs[idx]\n",
    "\n",
    "            # Fovea localization\n",
    "            f_x = self.index[str(idx)]['Fovea_X']\n",
    "            f_y = self.index[str(idx)]['Fovea_Y']\n",
    "            fov = torch.FloatTensor([f_x, f_y])\n",
    "        \n",
    "            return img, lab, seg, fov, self.index[str(idx)]['ImgName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-7\n",
    "\n",
    "def compute_dice_coef(input, target):\n",
    "    '''\n",
    "    Compute dice score metric.\n",
    "    '''\n",
    "    batch_size = input.shape[0]\n",
    "    return sum([dice_coef_sample(input[k,:,:], target[k,:,:]) for k in range(batch_size)])/batch_size\n",
    "\n",
    "def dice_coef_sample(input, target):\n",
    "    iflat = input.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return (2. * intersection) / (iflat.sum() + tflat.sum())\n",
    "\n",
    "\n",
    "def vertical_diameter(binary_segmentation):\n",
    "    '''\n",
    "    Get the vertical diameter from a binary segmentation.\n",
    "    The vertical diameter is defined as the \"fattest\" area of the binary_segmentation parameter.\n",
    "    '''\n",
    "\n",
    "    # get the sum of the pixels in the vertical axis\n",
    "    vertical_axis_diameter = np.sum(binary_segmentation, axis=1)\n",
    "\n",
    "    # pick the maximum value\n",
    "    diameter = np.max(vertical_axis_diameter, axis=1)\n",
    "\n",
    "    # return it\n",
    "    return diameter\n",
    "\n",
    "\n",
    "\n",
    "def vertical_cup_to_disc_ratio(od, oc):\n",
    "    '''\n",
    "    Compute the vertical cup-to-disc ratio from a given labelling map.\n",
    "    '''\n",
    "    # compute the cup diameter\n",
    "    cup_diameter = vertical_diameter(oc)\n",
    "    # compute the disc diameter\n",
    "    disc_diameter = vertical_diameter(od)\n",
    "\n",
    "    return cup_diameter / (disc_diameter + EPS)\n",
    "\n",
    "def compute_vCDR_error(pred_od, pred_oc, gt_od, gt_oc):\n",
    "    '''\n",
    "    Compute vCDR prediction error, along with predicted vCDR and ground truth vCDR.\n",
    "    '''\n",
    "    pred_vCDR = vertical_cup_to_disc_ratio(pred_od, pred_oc)\n",
    "    gt_vCDR = vertical_cup_to_disc_ratio(gt_od, gt_oc)\n",
    "    vCDR_err = np.mean(np.abs(gt_vCDR - pred_vCDR))\n",
    "    return vCDR_err, pred_vCDR, gt_vCDR\n",
    "\n",
    "\n",
    "def classif_eval(classif_preds, classif_gts):\n",
    "    '''\n",
    "    Compute AUC classification score.\n",
    "    '''\n",
    "    auc = roc_auc_score(classif_gts, classif_preds)\n",
    "    return auc\n",
    "\n",
    "\n",
    "def fov_error(pred_fov, gt_fov):\n",
    "    '''\n",
    "    Fovea localization error metric (mean root squared error).\n",
    "    '''\n",
    "    err = np.sqrt(np.sum((gt_fov-pred_fov)**2, axis=1)).mean()\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_seg(pred):\n",
    "    '''\n",
    "    Only retain the biggest connected component of a segmentation map.\n",
    "    '''\n",
    "    np_pred = pred.numpy()\n",
    "        \n",
    "    largest_ccs = []\n",
    "    for i in range(np_pred.shape[0]):\n",
    "        labeled, ncomponents = label(np_pred[i,:,:])\n",
    "        bincounts = np.bincount(labeled.flat)[1:]\n",
    "        if len(bincounts) == 0:\n",
    "            largest_cc = labeled == 0\n",
    "        else:\n",
    "            largest_cc = labeled == np.argmax(bincounts)+1\n",
    "        largest_cc = torch.tensor(largest_cc, dtype=torch.float32)\n",
    "        largest_ccs.append(largest_cc)\n",
    "    largest_ccs = torch.stack(largest_ccs)\n",
    "    \n",
    "    return largest_ccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=2):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 \n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor)\n",
    "        self.up2 = Up(512, 256 // factor)\n",
    "        self.up3 = Up(256, 128 // factor)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.output_layer = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        out = self.up1(x5, x4)\n",
    "        out = self.up2(out, x3)\n",
    "        out = self.up3(out, x2)\n",
    "        out = self.up4(out, x1)\n",
    "        out = self.output_layer(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use the normal convolutions to reduce the number of channels\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    '''\n",
    "    Simple convolution.\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/kaggle/input/eurecom-aml-2021-challenge-2/refuge_data/refuge_data'\n",
    "lr = 1e-4\n",
    "batch_size = 8\n",
    "num_workers = 8\n",
    "total_epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets and data loaders\n",
    "All image files are loaded in RAM in order to speed up the pipeline. Therefore, each dataset creation should take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully loaded train dataset.                                                  \n",
      "Succesfully loaded val dataset.                                                  \n",
      "Succesfully loaded test dataset.                                                  \n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "train_set = RefugeDataset(root_dir, \n",
    "                          split='train')\n",
    "val_set = RefugeDataset(root_dir, \n",
    "                        split='val')\n",
    "test_set = RefugeDataset(root_dir, \n",
    "                         split='test')\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_set, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=False, \n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=True,\n",
    "                         )\n",
    "val_loader = DataLoader(val_set, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        num_workers=num_workers,\n",
    "                        pin_memory=True,\n",
    "                        )\n",
    "test_loader = DataLoader(test_set, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        num_workers=num_workers,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_batches = len(train_loader)\n",
    "nb_val_batches = len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device, model, loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# Network\n",
    "model = UNet(n_channels=3, n_classes=2).to(device)\n",
    "\n",
    "# Loss\n",
    "seg_loss = torch.nn.BCELoss(reduction='mean')\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for OC/OD segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to not shuffle the train data so that we can build other features for the moment outside the loop of the U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "nb_train_batches = len(train_loader)\n",
    "nb_val_batches = len(val_loader)\n",
    "nb_iter = 0\n",
    "best_val_auc = 0.\n",
    "\n",
    "while model.epoch < total_epoch:\n",
    "    # Accumulators\n",
    "    train_vCDRs, val_vCDRs = [], [] \n",
    "    train_classif_gts, val_classif_gts = [], []\n",
    "    train_loss, val_loss = 0., 0.\n",
    "    train_dsc_od, val_dsc_od = 0., 0.\n",
    "    train_dsc_oc, val_dsc_oc = 0., 0.\n",
    "    train_vCDR_error, val_vCDR_error = 0., 0.\n",
    "    \n",
    "    ############\n",
    "    # TRAINING #\n",
    "    ############\n",
    "    model.train()\n",
    "    train_data = iter(train_loader)\n",
    "    for k in range(nb_train_batches):\n",
    "        # Loads data\n",
    "        imgs, classif_gts, seg_gts, fov_coords, names = train_data.next()\n",
    "        imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(imgs)\n",
    "        loss = seg_loss(logits, seg_gts)\n",
    " \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() / nb_train_batches\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Compute segmentation metric\n",
    "            pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            gt_od = seg_gts[:,0,:,:].type(torch.int8)\n",
    "            gt_oc = seg_gts[:,1,:,:].type(torch.int8)\n",
    "            dsc_od = compute_dice_coef(pred_od, gt_od)\n",
    "            dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n",
    "            train_dsc_od += dsc_od.item()/nb_train_batches\n",
    "            train_dsc_oc += dsc_oc.item()/nb_train_batches\n",
    "\n",
    "\n",
    "            # Compute and store vCDRs\n",
    "            vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(pred_od.cpu().numpy(), pred_oc.cpu().numpy(), gt_od.cpu().numpy(), gt_oc.cpu().numpy())\n",
    "            train_vCDRs += pred_vCDR.tolist()\n",
    "            train_vCDR_error += vCDR_error / nb_train_batches\n",
    "            train_classif_gts += classif_gts.cpu().numpy().tolist()\n",
    "            \n",
    "        # Increase iterations\n",
    "        nb_iter += 1\n",
    "        \n",
    "        # Std out\n",
    "        print('Epoch {}, iter {}/{}, loss {:.6f}'.format(model.epoch+1, k+1, nb_train_batches, loss.item()) + ' '*20, \n",
    "              end='\\r')\n",
    "        \n",
    "    # Train a logistic regression on vCDRs\n",
    "    train_vCDRs = np.array(train_vCDRs).reshape(-1,1)\n",
    "    train_classif_gts = np.array(train_classif_gts)\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs').fit(train_vCDRs, train_classif_gts)\n",
    "    train_classif_preds = clf.predict_proba(train_vCDRs)[:,1]\n",
    "    train_auc = classif_eval(train_classif_preds, train_classif_gts)\n",
    "    \n",
    "    ##############\n",
    "    # VALIDATION #\n",
    "    ##############\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_data = iter(val_loader)\n",
    "        for k in range(nb_val_batches):\n",
    "            # Loads data\n",
    "            imgs, classif_gts, seg_gts, fov_coords, names = val_data.next()\n",
    "            imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(imgs)\n",
    "            val_loss += seg_loss(logits, seg_gts).item() / nb_val_batches\n",
    "\n",
    "            # Std out\n",
    "            print('Validation iter {}/{}'.format(k+1, nb_val_batches) + ' '*50, \n",
    "                  end='\\r')\n",
    "            \n",
    "            # Compute segmentation metric\n",
    "            pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            gt_od = seg_gts[:,0,:,:].type(torch.int8)\n",
    "            gt_oc = seg_gts[:,1,:,:].type(torch.int8)\n",
    "            dsc_od = compute_dice_coef(pred_od, gt_od)\n",
    "            dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n",
    "            val_dsc_od += dsc_od.item()/nb_val_batches\n",
    "            val_dsc_oc += dsc_oc.item()/nb_val_batches\n",
    "            \n",
    "            # Compute and store vCDRs\n",
    "            vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(pred_od.cpu().numpy(), pred_oc.cpu().numpy(), gt_od.cpu().numpy(), gt_oc.cpu().numpy())\n",
    "            val_vCDRs += pred_vCDR.tolist()\n",
    "            val_vCDR_error += vCDR_error / nb_val_batches\n",
    "            val_classif_gts += classif_gts.cpu().numpy().tolist()\n",
    "            \n",
    "            \n",
    "\n",
    "    # Glaucoma predictions from vCDRs\n",
    "    val_vCDRs = np.array(val_vCDRs).reshape(-1,1)\n",
    "    val_classif_gts = np.array(val_classif_gts)\n",
    "    val_classif_preds = clf.predict_proba(val_vCDRs)[:,1]\n",
    "    val_auc = classif_eval(val_classif_preds, val_classif_gts)\n",
    "        \n",
    "    # Validation results\n",
    "    print('VALIDATION epoch {}'.format(model.epoch+1)+' '*50)\n",
    "    print('LOSSES: {:.4f} (train), {:.4f} (val)'.format(train_loss, val_loss))\n",
    "    print('OD segmentation (Dice Score): {:.4f} (train), {:.4f} (val)'.format(train_dsc_od, val_dsc_od))\n",
    "    print('OC segmentation (Dice Score): {:.4f} (train), {:.4f} (val)'.format(train_dsc_oc, val_dsc_oc))\n",
    "    print('vCDR error: {:.4f} (train), {:.4f} (val)'.format(train_vCDR_error, val_vCDR_error))\n",
    "    print('Classification (AUC): {:.4f} (train), {:.4f} (val)'.format(train_auc, val_auc))\n",
    "    \n",
    "    # Save model if best validation AUC is reached\n",
    "    if val_auc > best_val_auc:\n",
    "        torch.save(model.state_dict(), '/kaggle/working/best_AUC_weights.pth')\n",
    "        with open('/kaggle/working/best_AUC_classifier.pkl', 'wb') as clf_file:\n",
    "            pickle.dump(clf, clf_file)\n",
    "        best_val_auc = val_auc\n",
    "        print('Best validation AUC reached. Saved model weights and classifier.')\n",
    "    print('_'*50)\n",
    "        \n",
    "    # End of epoch\n",
    "    model.epoch += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting weights of Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to save our weights fromerly computed so that we don't have to execute the U-net anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and classifier\n",
    "model = UNet(n_channels=3, n_classes=2).to(device)\n",
    "model.load_state_dict(torch.load('../input/best-auc-weightspth/best_AUC_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method that came to our mind to improve the accuracy was to create some features for each image and take them into account to train and use our classifier. We therefore created 26 features (some are very similar) and then tried to select the most pertinent one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "from skimage.measure import find_contours\n",
    "import skimage.morphology as morpho\n",
    "\n",
    "\n",
    "def average_contrast(ori, region):\n",
    "    \n",
    "    \"\"\"This function gives the features of the image which corresponds to the average contrast of the region\n",
    "    input : ori (original image), region (segmentation)\n",
    "    ouput : contrast_R, contrast_G, contrast_B the set of average contrast on every channel\"\"\"\n",
    "    \n",
    "    ori = np.array(ori)    #computing the gradient norm of the image\n",
    "    se=morpho.selem.disk(1)\n",
    "        \n",
    "    contrast = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(ori)) :\n",
    "        im = ori[i]\n",
    "        grad = morpho.dilation(im[:,:], se)- morpho.erosion(im[:,:], se)\n",
    "        \n",
    "        seg = region[i]\n",
    "        contrast.append(np.mean(grad[seg>0],axis=0))\n",
    "       \n",
    "        \n",
    "    return contrast\n",
    "def norm_grad(im):\n",
    "    sobelx = cv2.Sobel(im, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobely = cv2.Sobel(im, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    return(sobelx**2 + sobely**2)**0.5\n",
    "\n",
    "def featuresComputation(im, segCup, segDisc):\n",
    "    sumN = np.sum(segDisc)\n",
    "    features = []\n",
    "    #  ratio and areas\n",
    "    features.append(np.sum(segCup))\n",
    "    features.append(np.sum(segDisc))\n",
    "    features.append(np.sum(segDisc)/np.sum(segCup))\n",
    "    \n",
    "    # relative position\n",
    "    cCup = regionprops(segCup)[0].centroid\n",
    "    if sumN!=0:\n",
    "        cDisc = regionprops(segDisc)[0].centroid\n",
    "    else:\n",
    "        cDisc = (0,0)\n",
    "    features.append(cCup[0]-cDisc[0])  # decalage en x\n",
    "    features.append(cCup[1]-cDisc[1])  # decalage en y\n",
    "    \n",
    "    # eccentricity\n",
    "    features.append(regionprops(segCup)[0].eccentricity)\n",
    "    if sumN !=0:\n",
    "        features.append(regionprops(segDisc)[0].eccentricity)\n",
    "    else :\n",
    "        features.append(0)\n",
    "    \n",
    "    # major_axis_length\n",
    "    features.append(regionprops(segCup)[0].major_axis_length)\n",
    "    if sumN !=0:\n",
    "        features.append(regionprops(segDisc)[0].major_axis_length)\n",
    "    else :\n",
    "        features.append(0)\n",
    "    \n",
    "    # minor_axis_length\n",
    "    features.append(regionprops(segCup)[0].minor_axis_length)\n",
    "    if sumN !=0:\n",
    "        features.append(regionprops(segDisc)[0].minor_axis_length)\n",
    "    else :\n",
    "        features.append(0)\n",
    "    \n",
    "    # perimeter\n",
    "    features.append(regionprops(segCup)[0].perimeter)\n",
    "    if sumN !=0:\n",
    "        features.append(regionprops(segDisc)[0].perimeter)\n",
    "    else :\n",
    "        features.append(0)\n",
    "    \n",
    "    # orientation\n",
    "    features.append(regionprops(segCup)[0].orientation)\n",
    "    if sumN !=0:\n",
    "        features.append(regionprops(segDisc)[0].orientation)\n",
    "    else :\n",
    "        features.append(0)\n",
    "    \n",
    "    if sumN !=0:\n",
    "        contours_Cup = find_contours(segCup,0.5)\n",
    "        contours_Disc = find_contours(segDisc,0.5)\n",
    "        tension1 = np.gradient(contours_Cup[0],axis=0)\n",
    "        tension2 = np.gradient(contours_Disc[0],axis=0)\n",
    "        features.append(np.abs(tension1).mean())\n",
    "        features.append(np.abs(tension2).mean())\n",
    "    \n",
    "        courbure1 = np.gradient(tension1,axis=0)\n",
    "        courbure2 = np.gradient(tension2,axis=0)\n",
    "        features.append(np.abs(courbure1).mean())\n",
    "        features.append(np.abs(courbure2).mean())\n",
    "    else : \n",
    "        features.append(0)\n",
    "        features.append(0)\n",
    "        features.append(0)\n",
    "        features.append(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # average intensity\n",
    "    av_Cup = (im*segCup).mean()\n",
    "    av_Disc = (im*segDisc).mean()\n",
    "    features.append(av_Cup)\n",
    "    features.append(av_Disc)\n",
    "        \n",
    "    # standard deviation \n",
    "    std_Cup = (im*segCup).std()\n",
    "    std_Disc = (im*segDisc).std()\n",
    "    features.append(std_Cup)\n",
    "    features.append(std_Disc)\n",
    "        \n",
    "    # gradient\n",
    "    grad_Cup = norm_grad(im*segCup).mean()\n",
    "    grad_Disc = norm_grad(im*segDisc).mean()\n",
    "    features.append(grad_Cup)\n",
    "    features.append(grad_Disc)        \n",
    "        \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have functions that can compute the wanted features we apply it to the dataset in order to train the classifier with them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Computing the right VCDRs (with the good weight)\n",
    "train_vCDRs = []\n",
    "train_classif_gts = []\n",
    "train_loss = 0.\n",
    "train_dsc_od = 0.\n",
    "train_dsc_oc = 0.\n",
    "train_vCDR_error = 0.\n",
    "\n",
    "Contrast = []\n",
    "\n",
    "FeaturesList = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_data = iter(train_loader)\n",
    "    for k in range(nb_train_batches):\n",
    "    \n",
    "            # Loads data\n",
    "            imgs, classif_gts, seg_gts, fov_coords, names = train_data.next()\n",
    "            imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n",
    "            logits = model(imgs)\n",
    "            \n",
    "            # Compute segmentation metric\n",
    "            pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            gt_od = seg_gts[:,0,:,:].type(torch.int8)\n",
    "            gt_oc = seg_gts[:,1,:,:].type(torch.int8)\n",
    "            dsc_od = compute_dice_coef(pred_od, gt_od)\n",
    "            dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n",
    "            train_dsc_od += dsc_od.item()/nb_val_batches\n",
    "            train_dsc_oc += dsc_oc.item()/nb_val_batches\n",
    "            \n",
    "            # Compute and store vCDRs\n",
    "            vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(pred_od.cpu().numpy(), pred_oc.cpu().numpy(), gt_od.cpu().numpy(), gt_oc.cpu().numpy())\n",
    "            train_vCDRs += pred_vCDR.tolist()\n",
    "            train_vCDR_error += vCDR_error / nb_val_batches\n",
    "            train_classif_gts += classif_gts.cpu().numpy().tolist()\n",
    "            \n",
    "            \n",
    "            # Computing the contrast Feature\n",
    "            \n",
    "            imgs = imgs.cpu()\n",
    "            logits = logits.cpu()\n",
    "\n",
    "            ctrs = average_contrast(imgs[:,0,:,:],logits[:,0,:,:])    \n",
    "            Contrast += ctrs\n",
    "            # Computing the other features\n",
    "            features = []\n",
    "            for i in range (8):\n",
    "                features.append(featuresComputation(imgs[i,0,:,:].numpy(), (logits[i,1,:,:].numpy()>0.1).astype(int), (logits[i,0,:,:].numpy()>0.1).astype(int)))\n",
    "            FeaturesList += features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we combine every features in the same array and make a DataFrame for readability and analysis. We need to select the most pertinent feature. (too much feature is no good for our accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       VCDR  Contrast  SumCup  SumDisc  RationSum     X_Gap     y_Gap  \\\n",
      "0  0.659091  0.025032   603.0   1395.0   2.313433 -0.337902 -0.189590   \n",
      "1  0.794872  0.026834   727.0   1012.0   1.392022  1.302692 -0.097307   \n",
      "2  0.735294  0.026927   526.0    888.0   1.688213  0.300196 -0.751927   \n",
      "3  0.636364  0.030969   338.0    811.0   2.399408  0.219256  0.538046   \n",
      "4  0.487805  0.038205   355.0   1218.0   3.430986  1.111053  3.595819   \n",
      "\n",
      "    Cup_Ecc  Disc_Ecc  Major_Axis_Cup  ...  Tension_disk  Courbure_cup  \\\n",
      "0  0.435034  0.463838       29.215415  ...           0.5      0.081081   \n",
      "1  0.480473  0.551361       32.502602  ...           0.5      0.082000   \n",
      "2  0.242315  0.243012       26.276880  ...           0.5      0.082524   \n",
      "3  0.315244  0.381241       21.293367  ...           0.5      0.072289   \n",
      "4  0.140221  0.506395       21.361879  ...           0.5      0.079412   \n",
      "\n",
      "   Courbure_disk    av_Cup   av_Disk   std_cup  std_Disk  gradient_cup  \\\n",
      "0       0.093567  0.008109  0.016099  0.084857  0.112413      0.164331   \n",
      "1       0.082759  0.008128  0.009963  0.078195  0.082946      0.154795   \n",
      "2       0.080292  0.006639  0.009791  0.074486  0.085690      0.144409   \n",
      "3       0.083333  0.004468  0.008842  0.062452  0.080900      0.115821   \n",
      "4       0.091615  0.003975  0.010147  0.054669  0.077147      0.109307   \n",
      "\n",
      "   gradient_Disk  Label  \n",
      "0       0.235517    1.0  \n",
      "1       0.170827    1.0  \n",
      "2       0.173713    1.0  \n",
      "3       0.163231    1.0  \n",
      "4       0.172981    1.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "FeaturesList = np.array(FeaturesList).reshape(-1,25)\n",
    "train_vCDRs = np.array(train_vCDRs).reshape(-1,1)\n",
    "Contrast = np.array(Contrast).reshape(-1,1)\n",
    "features2 = np.concatenate((train_vCDRs,Contrast),axis=1)\n",
    "featuresAll = np.concatenate((train_vCDRs,Contrast,FeaturesList),axis=1)\n",
    "\n",
    "FeatureNames = ['VCDR','Contrast','SumCup','SumDisc','RationSum','X_Gap','y_Gap','Cup_Ecc','Disc_Ecc','Major_Axis_Cup','Major_axis_Disc','Minor_axis_Cup','Minor_axis_disk','Perimeter_cup','Perimeter_Disk','Orientation_Cup','Orientation_Disk','Tenstion_cup','Tension_disk','Courbure_cup','Courbure_disk','av_Cup','av_Disk','std_cup','std_Disk','gradient_cup','gradient_Disk','Label']\n",
    "\n",
    "Table = pd.DataFrame(np.concatenate((featuresAll,np.array(train_classif_gts).reshape(-1,1)),axis=1),columns=FeatureNames)\n",
    "\n",
    "print(Table.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection**\n",
    "\n",
    "In this case we have a numerical input, categorical output. This is a classification predictive modeling problem with numerical input variables. Again, the most common techniques are correlation based, although in this case, they must take the categorical target into account.\n",
    "\n",
    "Because of this we decided to use ANOVA correlation coefficient (linear) and the mutual information.\n",
    "\n",
    "Let's use Anova -f from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# configure to select all features\n",
    "fs = feature_selection.SelectKBest(k='all')\n",
    "\n",
    "X_train = Table[['VCDR','Contrast','SumCup','SumDisc','RationSum','X_Gap','y_Gap','Cup_Ecc','Disc_Ecc','Major_Axis_Cup','Major_axis_Disc','Minor_axis_Cup','Minor_axis_disk','Perimeter_cup','Perimeter_Disk','Orientation_Cup','Orientation_Disk','Tenstion_cup','Tension_disk','Courbure_cup','Courbure_disk','av_Cup','av_Disk','std_cup','std_Disk','gradient_cup','gradient_Disk']]\n",
    "y_train = np.array(Table['Label']).reshape(-1,1)\n",
    "# learn relationship from training data\n",
    "fs.fit(X_train,y_train)\n",
    "\n",
    "# plot the scores\n",
    "plt.bar(['VCDR','Contrast','SumCup','SumDisc','RationSum','X_Gap','y_Gap','Cup_Ecc','Disc_Ecc','Major_Axis_Cup','Major_axis_Disc','Minor_axis_Cup','Minor_axis_disk','Perimeter_cup','Perimeter_Disk','Orientation_Cup','Orientation_Disk','Tenstion_cup','Tension_disk','Courbure_cup','Courbure_disk','av_Cup','av_Disk','std_cup','std_Disk','gradient_cup','gradient_Disk'], fs.scores_)\n",
    "plt.xticks(rotation=90,fontsize=8, fontname='monospace')\n",
    "plt.yticks(fontsize=20, fontname='monospace')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clearly shows that feature VCDRs / SumCup / Major_Axis_Cup / Minor_axis_Cup / Perimeter_Cup /av_cup / std_cup / gradient_cup might be the most relevant (according to test) and that perhaps six of the eight input features are the more relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute **the mutual information** to confirm our result from adova. The scikit-learn machine learning library provides an implementation of mutual information for feature selection with numeric input and categorical output variables via the mutual_info_classif() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # configure to select all features\n",
    "fs = feature_selection.SelectKBest(score_func=feature_selection.mutual_info_classif, k='all')\n",
    "# learn relationship from training data\n",
    "fs.fit(X_train, y_train)\n",
    "\n",
    "# plot the scores\n",
    "plt.bar(['VCDR','Contrast','SumCup','SumDisc','RationSum','X_Gap','y_Gap','Cup_Ecc','Disc_Ecc','Major_Axis_Cup','Major_axis_Disc','Minor_axis_Cup','Minor_axis_disk','Perimeter_cup','Perimeter_Disk','Orientation_Cup','Orientation_Disk','Tenstion_cup','Tension_disk','Courbure_cup','Courbure_disk','av_Cup','av_Disk','std_cup','std_Disk','gradient_cup','gradient_Disk'], fs.scores_)\n",
    "plt.xticks(rotation=90,fontsize=8, fontname='monospace')\n",
    "plt.yticks(fontsize=20, fontname='monospace')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms the selection of feature that ADOVA gave. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to select a combinaison of those that gives us the best results. We didn't find any other way than the very simple empiric way of testing with several combinaison. The results on the validation set are at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We test different combinaison of features (from the ones with some correlation)\n",
    "\n",
    "#a simple pre-precessing step\n",
    "X_scaler = StandardScaler().fit(featuresAll)\n",
    "featuresAll = X_scaler.transform(featuresAll)\n",
    "\n",
    "selectedFeatures1 = featuresAll[:,(0,2,4,9,11,13)]\n",
    "selectedFeatures2 = featuresAll[:,(0,2,4,9,11,13,21,23,25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "\n",
    "We decided to separate the feature extraction and the classification so that we have a clearer way of introducing new \n",
    "features to the process. We are training several classifier to compare the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression on vCDRs with the good weight\n",
    "train_classif_gts = np.array(train_classif_gts).reshape(-1,1)\n",
    "train_vCDRs =  np.array(train_vCDRs).reshape(-1,1)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(train_vCDRs, train_classif_gts)\n",
    "train_classif_preds = clf.predict_proba(train_vCDRs)[:,1]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression with the selected features\n",
    "\n",
    "clf2 = LogisticRegression(random_state=0, solver='lbfgs').fit(selectedFeatures1, train_classif_gts)\n",
    "\n",
    "clf3 = LogisticRegression(random_state=0, solver='lbfgs').fit(selectedFeatures2, train_classif_gts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result aren't that encouraging when using logistic regression on a selection of features. Let's try to use random forest, this model is very transparent an would give us information on where to improve our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc1 = RFC(random_state=0)\n",
    "rfc1.fit(selectedFeatures1,train_classif_gts)\n",
    "\n",
    "rfc2 = RFC(random_state=0)\n",
    "rfc2.fit(selectedFeatures2,train_classif_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the classifier will be compared when testing on the validation set, after trying the second method. The goal is two compare the two ways we designed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a CNN directly on the picture \n",
    "\n",
    "Glaucoma displays its main clinical symptoms in the optic disc region. Based on this mechanism, with optic disc segmentation predictions, we first crop the regions of interest and resize the patches to size 60*60 to exclude irrelevant\n",
    "background contexts. \n",
    "\n",
    "In order to improve our results we use Histogram equalization, CLAHE, for contrast enhancement\n",
    "and normalization so that even though the images are not taken in the exact same condition it should be processed correclty as a whole. \n",
    "\n",
    "The image are therefore enhanced and way smaller so they can be processed by a CNN directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting progressbar\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "Building wheels for collected packages: progressbar\n",
      "  Building wheel for progressbar (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12075 sha256=490333b8c7574168695ac030d449516b14f2d6d8ccd7168e1d9091f5e02e897b\n",
      "  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\n",
      "Successfully built progressbar\n",
      "Installing collected packages: progressbar\n",
      "Successfully installed progressbar-2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "\n",
    "# create a CLAHE object .\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "imagesTrain = []\n",
    "sick_vector_train = []\n",
    "threshold = 0.5\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_data = iter(train_loader)\n",
    "    for k in pbar(range(nb_train_batches)):\n",
    "        # Loads data\n",
    "        imgs, classif_gts, seg_gts, fov_coords, names = train_data.next()\n",
    "        imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n",
    "\n",
    "        logits = model(imgs)\n",
    "\n",
    "        imgs = imgs.cpu()\n",
    "        logits = logits.cpu()\n",
    "        masks = np.array(refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8)))\n",
    "        for p in range (len(imgs[:,0,:,:])):\n",
    "            x = []\n",
    "            y = []\n",
    "            mask = masks[p]\n",
    "            sick_vector_train.append(classif_gts[p].item())\n",
    "            for i in range (mask.shape[0]):\n",
    "                for j in range (mask.shape[1]):\n",
    "                    if mask[i][j]>threshold:\n",
    "                        x.append(i)\n",
    "                        y.append(j)\n",
    "                       \n",
    "            imga = imgs[p,:,:,:].numpy()[:,max(round(np.mean(x))-30,0):min(round(np.mean(x))+30,256),max(round(np.mean(y))-30,0):min(round(np.mean(y))+30,256)]\n",
    "            \n",
    "            \n",
    "             #Let's resize those that weren't well done \n",
    "            if(imga.shape) != (3,60, 60):\n",
    "                image = np.zeros((3,60,60))\n",
    "                for idx in range(len(imga)):\n",
    "                    img = imga[idx, :, :]\n",
    "                    img_sm = cv2.resize(img, (60, 60), interpolation=cv2.INTER_CUBIC)\n",
    "                    image[idx, :, :] = img_sm\n",
    "                imga = image\n",
    "            \n",
    "            #that allows to have the dimension in the right order !\n",
    "            imae = np.zeros((60,60,3))\n",
    "            for i in range(3):\n",
    "                imae[:,:,i] = clahe.apply((imga[i,:,:]*255).astype(np.uint8))\n",
    "                \n",
    "            imagesTrain.append(np.array(imae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "## Let's do the same with the validation data \n",
    "pbar = ProgressBar()\n",
    "\n",
    "imagesVal = []\n",
    "sick_vector_Val = []\n",
    "with torch.no_grad():\n",
    "    val_data = iter(val_loader)\n",
    "    for k in pbar(range(nb_val_batches)):\n",
    "        # Loads data\n",
    "        imgs, classif_gts, seg_gts, fov_coords, names = val_data.next()\n",
    "        imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n",
    "\n",
    "        logits = model(imgs)\n",
    "\n",
    "        imgs = imgs.cpu()\n",
    "        logits = logits.cpu()\n",
    "        masks = np.array(refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8)))\n",
    "        for p in range (len(imgs[:,0,:,:])):\n",
    "            x = []\n",
    "            y = []\n",
    "            mask = masks[p]\n",
    "            sick_vector_Val.append(classif_gts[p].item())\n",
    "            for i in range (mask.shape[0]):\n",
    "                for j in range (mask.shape[1]):\n",
    "                    if mask[i][j]>threshold:\n",
    "                        x.append(i)\n",
    "                        y.append(j)\n",
    "                       \n",
    "          \n",
    "            imga = imgs[p,:,:,:].numpy()[:,max(round(np.mean(x))-30,0):min(round(np.mean(x))+30,256),max(round(np.mean(y))-30,0):min(round(np.mean(y))+30,256)]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #Let's resize those that weren't well done \n",
    "            if(imga.shape) != (3,60, 60):\n",
    "                image = np.zeros((3,60,60))\n",
    "                for idx in range(len(imga)):\n",
    "                    img = imga[idx, :, :]\n",
    "                    img_sm = cv2.resize(img, (60, 60), interpolation=cv2.INTER_CUBIC)\n",
    "                    image[idx, :, :] = img_sm\n",
    "                imga = image\n",
    "            \n",
    "\n",
    "            #that allows to have the dimension in the right order !\n",
    "            imae = np.zeros((60,60,3))\n",
    "            for i in range(3):\n",
    "                #We apply the histogram equalization CLAHE\n",
    "                imae[:,:,i] = clahe.apply((imga[i,:,:]*255).astype(np.uint8))\n",
    "\n",
    "                    \n",
    "            imagesVal.append(np.array(imae))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : We wanted to use the high resolution image and then apply to it the segmentation mask but getting the real image means having another dimensions and therefore the mask won't work on the high resolution image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the right images (focused on the usefull zone) we are going to pre-process it so that it can bu use in several neural-networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sick_vector_Train = np.array(sick_vector_train).reshape(-1,1)\n",
    "imagesTrain=np.array(imagesTrain)\n",
    "X_train_cnn = imagesTrain.reshape(imagesTrain.shape[0], 60, 60, 3)\n",
    "\n",
    "sick_vector_Val = np.array(sick_vector_Val).reshape(-1,1)\n",
    "imagesVal=np.array(imagesVal)\n",
    "X_val_cnn = imagesVal.reshape(imagesVal.shape[0], 60, 60, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance of the models we decided to use a part of the validation set to train the models.\n",
    "So now we have the training and validation set to train and we took out a 100 images out of the validation set \n",
    "to validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create the new training set\n",
    "new_sick_vector_Train = np.concatenate((sick_vector_Train,sick_vector_Val[-250:]),axis=0)\n",
    "new_Xtrain_cnn = np.concatenate((X_train_cnn,X_val_cnn[-250:]),axis=0)\n",
    "\n",
    "\n",
    "\n",
    "#Let's create the new validation set \n",
    "\n",
    "new_sick_vector_Val = sick_vector_Val[:150]\n",
    "new_Xval_cnn = X_val_cnn[:150]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use Data Augmentation : We are creating some images from the ones we have in order to improve the accuracy of our models. Those tools also allows to have the right format input objects for our Keras nets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images will be rescaled by 1./255. , the rest should prevent from overfitting, since we are using a small data set it can\n",
    "#be a problem\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255.,rotation_range = 40,width_shift_range=0.2,height_shift_range=0.2,\n",
    "                                  shear_range=0.2,zoom_range=0.2)\n",
    "# --------------------\n",
    "# Flow training images in batches of batch_size using train_datagen generator\n",
    "# --------------------\n",
    "train_generator = train_datagen.flow(new_Xtrain_cnn,new_sick_vector_Train,batch_size=batch_size)\n",
    "\n",
    "# All images will be rescaled by 1./255.\n",
    "val_datagen = ImageDataGenerator( rescale = 1.0/255.)\n",
    "# --------------------\n",
    "# Flow training images in batches of batch_size using train_datagen generator\n",
    "# --------------------\n",
    "val_generator =  val_datagen.flow(new_Xval_cnn,new_sick_vector_Val,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's try several neural net**\n",
    "\n",
    "Our goal is to try a few nets and compare the results to select the most suited one.\n",
    "\n",
    "**The first one is a simple homemade CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 60, 60, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 60, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 30, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 15, 15, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 7,325,057\n",
      "Trainable params: 7,323,137\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn2 = Sequential()\n",
    "model_cnn2.add(layers.Conv2D(input_shape=(60,60,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model_cnn2.add(layers.BatchNormalization())\n",
    "model_cnn2.add(layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model_cnn2.add(layers.Conv2D(filters=128,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model_cnn2.add(layers.BatchNormalization())\n",
    "model_cnn2.add(layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model_cnn2.add(layers.Conv2D(filters=256,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model_cnn2.add(layers.BatchNormalization())\n",
    "model_cnn2.add(layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model_cnn2.add(layers.Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model_cnn2.add(layers.BatchNormalization())\n",
    "model_cnn2.add(layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model_cnn2.add(layers.Flatten())\n",
    "model_cnn2.add(layers.Dense(units=1024,activation=\"relu\"))\n",
    "model_cnn2.add(layers.Dense(units=1024,activation=\"relu\"))\n",
    "model_cnn2.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compiling the CNN\n",
    "model_cnn2.compile(loss = 'binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-4),\n",
    "              metrics = ['acc'])\n",
    "\n",
    "\n",
    "#Saving the best model\n",
    "\n",
    "checkpoint_path = \"./modelCnn.h5\"\n",
    "\n",
    "\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 save_best_only = True)\n",
    "model_cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "82/82 [==============================] - 5s 20ms/step - loss: 0.6276 - acc: 0.8758 - val_loss: 0.8488 - val_acc: 0.1000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.84876, saving model to ./modelCnn.h5\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.3170 - acc: 0.8862 - val_loss: 0.8914 - val_acc: 0.1000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.84876\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.2440 - acc: 0.9129 - val_loss: 1.1983 - val_acc: 0.1000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.84876\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.2895 - acc: 0.9230 - val_loss: 0.8217 - val_acc: 0.2667\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.84876 to 0.82168, saving model to ./modelCnn.h5\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.2657 - acc: 0.9111 - val_loss: 1.0240 - val_acc: 0.2200\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.82168\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1473 - acc: 0.9625 - val_loss: 0.3147 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.82168 to 0.31472, saving model to ./modelCnn.h5\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 1s 14ms/step - loss: 0.2395 - acc: 0.9232 - val_loss: 0.2048 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.31472 to 0.20481, saving model to ./modelCnn.h5\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1679 - acc: 0.9497 - val_loss: 0.1976 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.20481 to 0.19762, saving model to ./modelCnn.h5\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1821 - acc: 0.9424 - val_loss: 0.1819 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.19762 to 0.18189, saving model to ./modelCnn.h5\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.2399 - acc: 0.9062 - val_loss: 0.2374 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18189\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1547 - acc: 0.9447 - val_loss: 0.1646 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.18189 to 0.16455, saving model to ./modelCnn.h5\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 1s 18ms/step - loss: 0.1290 - acc: 0.9606 - val_loss: 0.1585 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.16455 to 0.15852, saving model to ./modelCnn.h5\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1830 - acc: 0.9362 - val_loss: 0.1809 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.15852\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1204 - acc: 0.9642 - val_loss: 0.1382 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.15852 to 0.13820, saving model to ./modelCnn.h5\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1444 - acc: 0.9627 - val_loss: 0.2161 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.13820\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1362 - acc: 0.9632 - val_loss: 0.1987 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.13820\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 1s 15ms/step - loss: 0.2279 - acc: 0.9133 - val_loss: 0.1918 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.13820\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1562 - acc: 0.9463 - val_loss: 0.2184 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.13820\n",
      "Epoch 19/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1103 - acc: 0.9505 - val_loss: 0.1739 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.13820\n",
      "Epoch 20/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1277 - acc: 0.9526 - val_loss: 0.1642 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.13820\n",
      "Epoch 21/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1004 - acc: 0.9716 - val_loss: 0.2227 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.13820\n",
      "Epoch 22/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1111 - acc: 0.9574 - val_loss: 0.1762 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.13820\n",
      "Epoch 23/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1262 - acc: 0.9535 - val_loss: 0.1602 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.13820\n",
      "Epoch 24/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1204 - acc: 0.9462 - val_loss: 0.1410 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.13820\n",
      "Epoch 25/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.0979 - acc: 0.9760 - val_loss: 0.2739 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.13820\n",
      "Epoch 26/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.0837 - acc: 0.9661 - val_loss: 0.5460 - val_acc: 0.7467\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.13820\n",
      "Epoch 27/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.1012 - acc: 0.9690 - val_loss: 0.2386 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.13820\n",
      "Epoch 28/30\n",
      "82/82 [==============================] - 1s 15ms/step - loss: 0.1522 - acc: 0.9445 - val_loss: 0.2774 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.13820\n",
      "Epoch 29/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.0971 - acc: 0.9563 - val_loss: 0.2143 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.13820\n",
      "Epoch 30/30\n",
      "82/82 [==============================] - 1s 12ms/step - loss: 0.0763 - acc: 0.9754 - val_loss: 0.3293 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.13820\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model_cnn2.fit(train_generator, validation_data = val_generator, epochs=30, verbose=1,callbacks = [cp_callback])\n",
    "\n",
    ",\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn2.load_weights('modelCnn.h5')\n",
    "model_cnn2.evaluate(new_Xtest_cnn, new_sick_vector_Test)\n",
    "test_classif_preds = model_cnn2.predict(new_X_val_cnn)\n",
    "val_aucCnn = classif_eval(test_classif_preds, new_sick_vector_Test)\n",
    "print('The AUC score value is :',val_aucCnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**\n",
    "\n",
    "This model gives us pretty a very good AUC. What we notice is that we had to find a balance in the complexity of the model. Too much layers created a very important overfitting phenomenon. (That's actually what's happening for the resNet).\n",
    "\n",
    "We also notice that the model with the best val_accuracy isn't the one that generalize the best, maybe that's because we use a large part of the validation set to train and therefor the result are better for some weights. (to explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also tried a pre-trained one, ResNet18 :** \n",
    "\n",
    "ResNet18 is a 18 layers deep model, so the process time is short, and according to what we read is very suited for image classification like the one we do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "modelResNet18 = ResNet18((60, 60, 3), weights='imagenet')\n",
    "\n",
    "for layer in modelResNet18.layers[:]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "modelRes = Sequential()\n",
    "modelRes.add(modelResNet18)\n",
    "modelRes.add(layers.BatchNormalization())\n",
    "modelRes.add(layers.Flatten())\n",
    "modelRes.add(layers.Dense(units=1024,activation=\"relu\"))\n",
    "modelRes.add(layers.Dense(units=1024,activation=\"relu\"))\n",
    "modelRes.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "modelRes.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-6),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "82/82 [==============================] - 3s 22ms/step - loss: 0.6928 - accuracy: 0.8612 - val_loss: 0.6916 - val_accuracy: 0.9000\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6914 - accuracy: 0.8881 - val_loss: 0.6901 - val_accuracy: 0.9000\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6897 - accuracy: 0.8825 - val_loss: 0.6880 - val_accuracy: 0.9000\n",
      "Epoch 4/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6871 - accuracy: 0.9137 - val_loss: 0.6854 - val_accuracy: 0.9000\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6847 - accuracy: 0.9000 - val_loss: 0.6823 - val_accuracy: 0.9000\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6818 - accuracy: 0.8911 - val_loss: 0.6787 - val_accuracy: 0.9000\n",
      "Epoch 7/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6772 - accuracy: 0.9160 - val_loss: 0.6745 - val_accuracy: 0.9000\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6726 - accuracy: 0.9155 - val_loss: 0.6695 - val_accuracy: 0.9000\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 1s 16ms/step - loss: 0.6691 - accuracy: 0.8876 - val_loss: 0.6638 - val_accuracy: 0.9000\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6627 - accuracy: 0.8963 - val_loss: 0.6573 - val_accuracy: 0.9000\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6566 - accuracy: 0.8909 - val_loss: 0.6499 - val_accuracy: 0.9000\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6465 - accuracy: 0.9153 - val_loss: 0.6416 - val_accuracy: 0.9000\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6396 - accuracy: 0.9023 - val_loss: 0.6325 - val_accuracy: 0.9000\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6305 - accuracy: 0.9002 - val_loss: 0.6224 - val_accuracy: 0.9000\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 0.6212 - accuracy: 0.8966 - val_loss: 0.6117 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "historyRes = modelRes.fit(train_generator, validation_data = val_generator, epochs=15, verbose=1,batch_size=8)\n",
    "\n",
    "plt.plot(historyRes.history['accuracy'])\n",
    "plt.plot(historyRes.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Comments**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we think is happening here is an important overfitting, that seems to explain why the val_accuracy doesn't change.\n",
    "To prevent that we tried adding batchNormalization et use the imageGenerator tool but we haven't been able to avoid this problem. We would need more data to train the resNet. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check performance is maintained on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION                                                             \n",
      "LOSSES: 0.0106 (val)\n",
      "OD segmentation (Dice Score): 0.9183 (val)\n",
      "OC segmentation (Dice Score): 0.8373 (val)\n",
      "vCDR error: 0.2198 (val)\n",
      "Classification (AUC) with vCDRs: 0.8873 (val)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_vCDRs = []\n",
    "val_classif_gts = []\n",
    "val_loss = 0.\n",
    "val_dsc_od = 0.\n",
    "val_dsc_oc = 0.\n",
    "val_vCDR_error = 0.\n",
    "feature2 = []\n",
    "FeaturesList = []\n",
    "imagesCroppedVal = []\n",
    "\n",
    "# create a CLAHE object .\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_data = iter(val_loader)\n",
    "    for k in range(nb_val_batches):\n",
    "        # Loads data\n",
    "        imgs, classif_gts, seg_gts, fov_coords, names = val_data.next()\n",
    "        imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(imgs)\n",
    "        val_loss += seg_loss(logits, seg_gts).item() / nb_val_batches\n",
    "\n",
    "        # Std out\n",
    "        print('Validation iter {}/{}'.format(k+1, nb_val_batches) + ' '*50, \n",
    "              end='\\r')\n",
    "\n",
    "        # Compute segmentation metric\n",
    "        pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "        pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "        \n",
    "        gt_od = seg_gts[:,0,:,:].type(torch.int8)\n",
    "        gt_oc = seg_gts[:,1,:,:].type(torch.int8)\n",
    "        dsc_od = compute_dice_coef(pred_od, gt_od)\n",
    "        dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n",
    "        val_dsc_od += dsc_od.item()/nb_val_batches\n",
    "        val_dsc_oc += dsc_oc.item()/nb_val_batches\n",
    "\n",
    "        # Compute and store vCDRs\n",
    "        vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(pred_od.cpu().numpy(), pred_oc.cpu().numpy(), gt_od.cpu().numpy(), gt_oc.cpu().numpy())\n",
    "        val_vCDRs += pred_vCDR.tolist()\n",
    "        val_vCDR_error += vCDR_error / nb_val_batches\n",
    "        val_classif_gts += classif_gts.cpu().numpy().tolist()\n",
    "        \n",
    "        \n",
    "        logits = model(imgs)\n",
    "        imgs = imgs.cpu()\n",
    "        logits = logits.cpu()\n",
    "        \n",
    "        contrast = average_contrast(imgs[:,0,:,:],logits[:,0,:,:])    \n",
    "        feature2 += contrast\n",
    "        \n",
    "        features = []\n",
    "    \n",
    "        for i in range (8):\n",
    "            features.append(featuresComputation(imgs[i,0,:,:].numpy(), (logits[i,0,:,:].numpy()>0.1).astype(int), (logits[i,1,:,:].numpy()>0.1).astype(int)))\n",
    "        FeaturesList += features\n",
    "        \n",
    "        \n",
    "        #Now the CNN method\n",
    "        \n",
    "        masks = np.array(refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8)))\n",
    "        for p in range (len(imgs[:,0,:,:])):\n",
    "            x = []\n",
    "            y = []\n",
    "            mask = masks[p]\n",
    "            \n",
    "            for i in range (mask.shape[0]):\n",
    "                for j in range (mask.shape[1]):\n",
    "                    if mask[i][j]>threshold:\n",
    "                        x.append(i)\n",
    "                        y.append(j)\n",
    "                       \n",
    "            imga = imgs[p,:,:,:].numpy()[:,max(round(np.mean(x))-30,0):min(round(np.mean(x))+30,256),max(round(np.mean(y))-30,0):min(round(np.mean(y))+30,256)]\n",
    "            \n",
    "            \n",
    "             #Let's resize those that weren't well done \n",
    "            if(imga.shape) != (3,60, 60):\n",
    "                image = np.zeros((3,60,60))\n",
    "                for idx in range(len(imga)):\n",
    "                    img = imga[idx, :, :]\n",
    "                    img_sm = cv2.resize(img, (60, 60), interpolation=cv2.INTER_CUBIC)\n",
    "                    image[idx, :, :] = img_sm\n",
    "                imga = image\n",
    "            \n",
    "            #that allows to have the dimension in the right order !\n",
    "            imae = np.zeros((60,60,3))\n",
    "            for i in range(3):\n",
    "                imae[:,:,i] = clahe.apply((imga[i,:,:]*255).astype(np.uint8))\n",
    "                \n",
    "            imagesCroppedVal.append(np.array(imae))\n",
    "            \n",
    "            \n",
    "imagesCroppedVal=np.array(imagesCroppedVal)\n",
    "X_cnn = imagesCroppedVal.reshape(imagesCroppedVal.shape[0], 60, 60, 3)\n",
    "\n",
    "model_cnn2.load_weights('modelCnn.h5')\n",
    "preds_cnn2 = model_cnn2.predict(X_cnn)\n",
    "val_aucCnn  = classif_eval(preds_cnn2.reshape(1,-1)[0], val_classif_gts)\n",
    "        \n",
    "preds_Res = modelRes.predict(X_cnn)\n",
    "val_aucRes  = classif_eval(preds_Res.reshape(1,-1)[0], val_classif_gts)\n",
    "        \n",
    "        \n",
    "        \n",
    "feature2 = np.array(feature2).reshape(-1,1)\n",
    "val_vCDRs = np.array(val_vCDRs).reshape(-1,1)\n",
    "FeaturesList = np.array(FeaturesList).reshape(-1,25)\n",
    "\n",
    "#Then we concatenate them to have one table of features\n",
    "features2 = np.concatenate((val_vCDRs,feature2),axis=1)\n",
    "featuresAll = np.concatenate((features2,FeaturesList),axis=1)\n",
    "featuresAll = X_scaler.transform(featuresAll)\n",
    "\n",
    "#And we select the ones usefull\n",
    "selectedFeatures1 = featuresAll[:,(0,2,4,9,11,13)]\n",
    "selectedFeatures2 = featuresAll[:,(0,2,4,9,11,13,21,23,25)]\n",
    "        \n",
    "# Glaucoma predictions from vCDRs\n",
    "\n",
    "val_classif_gts = np.array(val_classif_gts)\n",
    "\n",
    "val_classif_preds = clf.predict_proba(val_vCDRs)[:,1]\n",
    "val_auc = classif_eval(val_classif_preds, val_classif_gts)\n",
    "\n",
    "val_classif_preds2 = clf2.predict_proba(selectedFeatures1)[:,1]\n",
    "val_auc2 = classif_eval(val_classif_preds2, val_classif_gts)\n",
    "\n",
    "val_classif_preds3 = clf3.predict_proba(selectedFeatures2)[:,1]\n",
    "val_auc3 = classif_eval(val_classif_preds3, val_classif_gts)\n",
    "\n",
    "\n",
    "# Let's try the RFC\n",
    "\n",
    "val_classif_preds_RFC_1 = rfc1.predict_proba(selectedFeatures1)[:,1]\n",
    "val_auc_rfc_1 = classif_eval(val_classif_preds_RFC_1, val_classif_gts)\n",
    "\n",
    "val_classif_preds_RFC_2 = rfc2.predict_proba(selectedFeatures2)[:,1]\n",
    "val_auc_rfc_2  = classif_eval(val_classif_preds_RFC_2, val_classif_gts)\n",
    "\n",
    "\n",
    "# Validation results\n",
    "print('VALIDATION '+' '*50)\n",
    "print('LOSSES: {:.4f} (val)'.format(val_loss))\n",
    "print('OD segmentation (Dice Score): {:.4f} (val)'.format(val_dsc_od))\n",
    "print('OC segmentation (Dice Score): {:.4f} (val)'.format(val_dsc_oc))\n",
    "print('vCDR error: {:.4f} (val)'.format(val_vCDR_error))\n",
    "print('Classification (AUC) with vCDRs: {:.4f} (val)'.format(val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the results of our different methods\n",
    "Results = [val_auc,val_auc2,val_auc3,val_auc_rfc_1,val_auc_rfc_2,val_aucCnn,val_aucRes]\n",
    "labels = [\"LR_vCDRS\", \"LR_select1\", \"LR_select2\", \"RF_select1\", \"RF_select2\", \"CNN\", \"ResNet\"]\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "rects1 = plt.bar(labels, np.round(Results,2), width)\n",
    "plt.xticks(rotation=90,fontsize=8, fontname='monospace')\n",
    "plt.bar_label(rects1, padding=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results Comment:**\n",
    "\n",
    "What we see here is that no combination of features beats the use of vCDRs alone. We have tried a lot of combinaison from 25 features but every time the AUC goes down.\n",
    "We tried using the random forst classifier but it also fails to push the accuracy up. \n",
    "What we concluded of this results is that there is few data to train correctly those models (400 inputs) so the models don't generalize correctly.\n",
    "\n",
    "We have another method using CNN direclty on the zone of interest and we believe that this second method have much more potential than the classic use of features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0t iter 50/50                                                  \n",
      "6.0176015e-31\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.18386385\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.4818355e-28\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.8443324e-12\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.2990089e-29\n",
      "0.0\n",
      "0.15644509\n",
      "0.0\n",
      "4.4905396e-10\n",
      "1.0\n",
      "0.0\n",
      "1.9290578e-06\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "9.448952e-21\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.99999976\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.9211912e-32\n",
      "1.0\n",
      "0.9999927\n",
      "2.8215512e-26\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.872682e-10\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.3298505e-07\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.010090872\n",
      "2.4464345e-35\n",
      "1.2486426e-12\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.789781e-28\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "6.3552424e-25\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "2.0552242e-33\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0456101e-13\n",
      "1.0\n",
      "5.815321e-08\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.193393e-36\n",
      "0.0\n",
      "2.1055587e-27\n",
      "0.0\n",
      "0.0\n",
      "2.8304572e-14\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "2.6310238e-22\n",
      "0.0\n",
      "0.0\n",
      "6.5468035e-26\n",
      "0.0\n",
      "0.0\n",
      "3.0476303e-23\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.157541e-22\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.7010023e-31\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "8.9220104e-32\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.25584e-30\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "4.047786e-16\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "8.011139e-16\n",
      "0.0\n",
      "0.17332119\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.0285818e-09\n",
      "1.0\n",
      "1.0\n",
      "2.2357668e-38\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.99944633\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "nb_test_batches = len(test_loader)\n",
    "model.eval()\n",
    "test_vCDRs = []\n",
    "feature = []\n",
    "imagesCroppedTest = []\n",
    "\n",
    "# create a CLAHE object .\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_data = iter(test_loader)\n",
    "    for k in range(nb_test_batches):\n",
    "        # Loads data\n",
    "        imgs = test_data.next()\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(imgs)\n",
    "        \n",
    "\n",
    "        # Std out\n",
    "        print('Test iter {}/{}'.format(k+1, nb_test_batches) + ' '*50, \n",
    "              end='\\r')\n",
    "            \n",
    "        # Compute segmentation\n",
    "        pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "        pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            \n",
    "        # Compute and store vCDRs\n",
    "        pred_vCDR = vertical_cup_to_disc_ratio(pred_od.cpu().numpy(), pred_oc.cpu().numpy())\n",
    "        test_vCDRs += pred_vCDR.tolist()\n",
    "        \n",
    "        imgs = imgs.cpu()\n",
    "        logits = logits.cpu()\n",
    "        \n",
    "        masks = np.array(refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8)))\n",
    "        for p in range (len(imgs[:,0,:,:])):\n",
    "            x = []\n",
    "            y = []\n",
    "            mask = masks[p]\n",
    "            \n",
    "            for i in range (mask.shape[0]):\n",
    "                for j in range (mask.shape[1]):\n",
    "                    if mask[i][j]>threshold:\n",
    "                        x.append(i)\n",
    "                        y.append(j)\n",
    "                       \n",
    "            imga = imgs[p,:,:,:].numpy()[:,max(round(np.mean(x))-30,0):min(round(np.mean(x))+30,256),max(round(np.mean(y))-30,0):min(round(np.mean(y))+30,256)]\n",
    "            \n",
    "            \n",
    "             #Let's resize those that weren't well done \n",
    "            if(imga.shape) != (3,60, 60):\n",
    "                image = np.zeros((3,60,60))\n",
    "                for idx in range(len(imga)):\n",
    "                    img = imga[idx, :, :]\n",
    "                    img_sm = cv2.resize(img, (60, 60), interpolation=cv2.INTER_CUBIC)\n",
    "                    image[idx, :, :] = img_sm\n",
    "                imga = image\n",
    "            \n",
    "            #that allows to have the dimension in the right order !\n",
    "            imae = np.zeros((60,60,3))\n",
    "            for i in range(3):\n",
    "                imae[:,:,i] = clahe.apply((imga[i,:,:]*255).astype(np.uint8))\n",
    "                \n",
    "            imagesCroppedTest.append(np.array(imae))\n",
    "            \n",
    "            \n",
    "    imagesCroppedTest=np.array(imagesCroppedTest)\n",
    "    X_cnn = imagesCroppedTest.reshape(imagesCroppedTest.shape[0], 60, 60, 3)\n",
    "            \n",
    "    model_cnn2.load_weights('modelCnn.h5')\n",
    "    test_classif_preds = model_cnn2.predict(X_cnn)\n",
    "    \n",
    "    #Glaucoma predictions from vCDRs\n",
    "    #test_vCDRs = np.array(test_vCDRs).reshape(-1,1)\n",
    "    #features = np.concatenate((test_vCDRs,feature2),axis=1)\n",
    "    #test_classif_preds = clf2.predict_proba(features)[:,1]\n",
    "    \n",
    "# Prepare and save .csv file\n",
    "def create_submission_csv(prediction, submission_filename='/kaggle/working/submission3.csv'):\n",
    "    \"\"\"Create a sumbission file in the appropriate format for evaluation.\n",
    "\n",
    "    :param\n",
    "    prediction: list of predictions (ex: [0.12720, 0.89289, ..., 0.29829])\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(submission_filename, mode='w') as csv_file:\n",
    "        fieldnames = ['Id', 'Predicted']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for i, p in enumerate(prediction):\n",
    "            \n",
    "            writer.writerow({'Id': \"T{:04d}\".format(i+1), 'Predicted': '{:f}'.format(p)})\n",
    "\n",
    "create_submission_csv(test_classif_preds.reshape(1,-1)[0])\n",
    "\n",
    "# The submission.csv file is under /kaggle/working/submission.csv.\n",
    "# If you want to submit it, you should download it before closing the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
